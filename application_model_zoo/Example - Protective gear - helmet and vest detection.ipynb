{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Protective%20gear%20-%20helmet%20and%20vest%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## 1. Installation Instructions\n",
    "\n",
    "\n",
    "\n",
    "## 2. Use trained model to detect safety vest and helmet\n",
    "\n",
    "\n",
    "\n",
    "## 3. How to train using MMdetection wrapper and Personal-Protective-Equipment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    " - Run these commands\n",
    "     \n",
    "     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "     \n",
    "     - cd Monk_Object_Detection/16_mmdet/installation\n",
    "     \n",
    " - Select the right file and run\n",
    " \n",
    "     - chmod +x install.sh && ./install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd Monk_Object_Detection/16_mmdet/installation && chmod +x install.sh && ./install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use already trained model for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/16_mmdet/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_engine import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1P8dUOhXTeMu4NmYnzJA-xVbz51sCIkRk' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1P8dUOhXTeMu4NmYnzJA-xVbz51sCIkRk\" -O obj_ppe_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq obj_ppe_trained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model_Params(\"work_dirs/config_updated/config_updated.py\", \n",
    "                 \"work_dirs/config_updated/latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def print_result(input_img_name, result, output_img_name, thresh=0.3):\n",
    "    img = cv2.imread(input_img_name, 1);\n",
    "    for i in range(len(result)):\n",
    "        for j in range(len(result[i])):\n",
    "            x1 = int(result[i][j][0]);\n",
    "            y1 = int(result[i][j][1]);\n",
    "            x2 = int(result[i][j][2]);\n",
    "            y2 = int(result[i][j][3]);\n",
    "            score = float(result[i][j][4]);\n",
    "            if(score > thresh):\n",
    "                if(i == 0):\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,255), 4)\n",
    "                elif(i == 1):\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 4)\n",
    "                elif(i == 2):\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 4)\n",
    "    cv2.imwrite(output_img_name, img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/7.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/7.jpg\", result, \"7.jpg\", thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/6.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/6.jpg\", result, \"6.jpg\", thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/5.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/5.jpg\", result, \"5.jpg\", thresh=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/2.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/2.jpg\", result, \"2.jpg\", thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/3.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/3.jpg\", result, \"3.jpg\", thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/4.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/4.jpg\", result, \"4.jpg\", thresh=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"work_dirs/test/1.jpg\",\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.1);\n",
    "\n",
    "print_result(\"work_dirs/test/1.jpg\", result, \"1.jpg\", thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training your own detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    " - Credits: https://github.com/ciber-lab/pictor-ppe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the file downloaded from gdrive in the mentioned directory structure\n",
    "\n",
    "    pictor-ppe\n",
    "       |----------Images\n",
    "       |----------Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir dataset\n",
    "\n",
    "! mkdir dataset/train\n",
    "! mkdir dataset/train/images\n",
    "! mkdir dataset/valid\n",
    "! mkdir dataset/valid/images\n",
    "! mkdir dataset/test\n",
    "! mkdir dataset/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion - Current format to Monk format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"pictor-ppe/Labels/pictor_ppe_crowdsourced_approach-01_train.txt\");\n",
    "lines = f.readlines();\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    stats = lines[i][:len(lines[i])-1].split(\"\\t\");\n",
    "    img_name = stats[0];\n",
    "    img = cv2.imread(\"pictor-ppe/Images/\" + img_name)\n",
    "    wr = \"\";\n",
    "    for j in range(1, len(stats)):\n",
    "        tmp = stats[j].split(\",\");\n",
    "        x1 = tmp[0];\n",
    "        y1 = tmp[1];\n",
    "        x2 = tmp[2];\n",
    "        y2 = tmp[3];\n",
    "        label = tmp[4];\n",
    "        if(label == \"0\"):\n",
    "            label = \"helmet\";\n",
    "        elif(label == \"1\"):\n",
    "            label = \"safety_vest\";\n",
    "        else:\n",
    "            label = \"person\";\n",
    "        wr += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "        \n",
    "    wr = wr[:len(wr)-1]\n",
    "    combined.append([str(i) + \".jpg\", wr]);\n",
    "        \n",
    "    cv2.imwrite(\"dataset/train/images/\" + str(i) + \".jpg\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['Img_Name', 'Label']);\n",
    "df.to_csv(\"dataset/train/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"pictor-ppe/Labels/pictor_ppe_crowdsourced_approach-01_valid.txt\");\n",
    "lines = f.readlines();\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    stats = lines[i][:len(lines[i])-1].split(\"\\t\");\n",
    "    img_name = stats[0];\n",
    "    img = cv2.imread(\"pictor-ppe/Images/\" + img_name)\n",
    "    wr = \"\";\n",
    "    for j in range(1, len(stats)):\n",
    "        tmp = stats[j].split(\",\");\n",
    "        x1 = tmp[0];\n",
    "        y1 = tmp[1];\n",
    "        x2 = tmp[2];\n",
    "        y2 = tmp[3];\n",
    "        label = tmp[4];\n",
    "        if(label == \"0\"):\n",
    "            label = \"helmet\";\n",
    "        elif(label == \"1\"):\n",
    "            label = \"safety_vest\";\n",
    "        else:\n",
    "            label = \"person\";\n",
    "        wr += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "        \n",
    "    wr = wr[:len(wr)-1]\n",
    "    combined.append([str(i) + \".jpg\", wr]);\n",
    "        \n",
    "    cv2.imwrite(\"dataset/valid/images/\" + str(i) + \".jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['Img_Name', 'Label']);\n",
    "df.to_csv(\"dataset/valid/valid_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"pictor-ppe/Labels/pictor_ppe_crowdsourced_approach-01_test.txt\");\n",
    "lines = f.readlines();\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    stats = lines[i][:len(lines[i])-1].split(\"\\t\");\n",
    "    img_name = stats[0];\n",
    "    img = cv2.imread(\"pictor-ppe/Images/\" + img_name)\n",
    "    wr = \"\";\n",
    "    for j in range(1, len(stats)):\n",
    "        tmp = stats[j].split(\",\");\n",
    "        x1 = tmp[0];\n",
    "        y1 = tmp[1];\n",
    "        x2 = tmp[2];\n",
    "        y2 = tmp[3];\n",
    "        label = tmp[4];\n",
    "        if(label == \"0\"):\n",
    "            label = \"helmet\";\n",
    "        elif(label == \"1\"):\n",
    "            label = \"safety_vest\";\n",
    "        else:\n",
    "            label = \"person\";\n",
    "        wr += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "        \n",
    "    wr = wr[:len(wr)-1]\n",
    "    combined.append([str(i) + \".jpg\", wr]);\n",
    "        \n",
    "    cv2.imwrite(\"dataset/test/images/\" + str(i) + \".jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['Img_Name', 'Label']);\n",
    "df.to_csv(\"dataset/test/test_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion - Monk format to COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "root = \"dataset/train\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"train_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "\n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "root = \"dataset/valid\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"valid_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "\n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "root = \"dataset/test\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"test_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "\n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/16_mmdet/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_engine import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"dataset/train/images\";\n",
    "annofile = \"dataset/train/annotations/instances_images.json\"\n",
    "class_file = \"dataset/train/annotations/classes.txt\"\n",
    "\n",
    "gtf.Train_Dataset(img_dir, annofile, class_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"dataset/valid/images\";\n",
    "annofile = \"dataset/valid/annotations/instances_images.json\"\n",
    "\n",
    "gtf.Val_Dataset(img_dir, annofile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Dataset_Params(batch_size=2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.List_Models();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model_Params(model_name=\"cascade_rcnn_fpn101\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Hyper_Params(lr=0.02, momentum=0.9, weight_decay=0.0001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Training_Params(num_epochs=10, val_interval=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/16_mmdet/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_engine import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model_Params(\"work_dirs/config_updated/config_updated.py\", \n",
    "                 \"work_dirs/config_updated/latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_list = os.listdir(\"dataset/test/images\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"dataset/test/images/\" + img_list[0],\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.3);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='result.jpg', width=490, height=640) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"dataset/test/images/\" + img_list[2],\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.3);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='result.jpg', width=490, height=640) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

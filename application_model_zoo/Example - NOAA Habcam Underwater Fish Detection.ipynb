{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20NOAA%20Habcam%20Underwater%20Fish%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## 1. Installation Instructions\n",
    "\n",
    "\n",
    "## 2. How to train using MMdetection wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    " - Run these commands\n",
    "     \n",
    "     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "     \n",
    "     - cd Monk_Object_Detection/16_mmdet/installation\n",
    "     \n",
    " - Select the right file and run\n",
    " \n",
    "     - chmod +x install.sh && ./install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd Monk_Object_Detection/16_mmdet/installation && chmod +x install.sh && ./install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training your own detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    " - Credits: https://www.viametoolkit.org/cvpr-2018-workshop-data-challenge/challenge-data-description/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://challenge.kitware.com/api/v1/file/5adecdee56357d4ff85705f8/download -O data-challenge-training-imagery.tar.gz\n",
    "! wget https://challenge.kitware.com/api/v1/item/5ada39f756357d4ff856f550/download -O data-challenge-training-annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xzf data-challenge-training-imagery.tar.gz\n",
    "! tar -xzf data-challenge-training-annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir habcamseq0\n",
    "! mkdir habcamseq0/annotations\n",
    "! cp annotations/habcam_seq0_training.mscoco.json habcamseq0/annotations/instances_images.json\n",
    "! mv imagery/habcam_seq0 habcamseq0/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('habcamseq0/annotations/instances_images.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "g = open(\"habcamseq0/annotations/classes.txt\", 'w')\n",
    "for i in range(len(data[\"categories\"])):\n",
    "    g.write(data[\"categories\"][0][\"name\"] + \"\\n\");\n",
    "\n",
    "g.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/16_mmdet/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_engine import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"habcamseq0/images\";\n",
    "annofile = \"habcamseq0/annotations/instances_images.json\"\n",
    "class_file = \"habcamseq0/annotations/classes.txt\"\n",
    "\n",
    "gtf.Train_Dataset(img_dir, annofile, class_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Val_Dataset(img_dir, annofile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Dataset_Params(batch_size=8, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Model - faster_rcnn_fpn50\n",
      "2. Model - faster_rcnn_fpn101\n",
      "3. Model - faster_rcnn_x101_32x4d_fpn\n",
      "4. Model - faster_rcnn_x101_64x4d_fpn\n",
      "5. Model - cascade_rcnn_fpn50\n",
      "6. Model - cascade_rcnn_fpn101\n",
      "7. Model - cascade_rcnn_x101_32x4d_fpn\n",
      "8. Model - cascade_rcnn_x101_64x4d_fpn\n",
      "9. Model - retinanet_r50_fpn\n",
      "10. Model - retinanet_r101_fpn\n",
      "11. Model - retinanet_x101_32x4d_fpn\n",
      "12. Model - retinanet_x101_64x4d_fpn\n",
      "13. Model - retinanet_ghm_r50_fpn\n",
      "14. Model - retinanet_ghm_r101_fpn\n",
      "15. Model - retinanet_ghm_x101_32x4d_fpn\n",
      "16. Model - retinanet_ghm_x101_64x4d_fpn\n",
      "17. Model - dh_faster_rcnn_fpn50\n",
      "18. Model - libra_faster_rcnn_fpn50\n",
      "19. Model - libra_faster_rcnn_fpn101\n",
      "20. Model - libra_faster_rcnn_x101_64x4d_fpn\n",
      "21. Model - libra_retinanet_r50_fpn\n",
      "22. Model - ga_faster_rcnn_x101_32x4d_fpn\n",
      "23. Model - ga_faster_rcnn_x101_64x4d_fpn\n",
      "24. Model - ga_retinanet_x101_32x4d_fpn\n",
      "25. Model - ga_retinanet_x101_64x4d_fpn\n",
      "26. Model - fovea_r50_fpn_4x4\n",
      "27. Model - fovea_r101_fpn_4x4\n",
      "28. Model - fovea_align_r50_fpn_gn-head_mstrain_640-800_4x4\n",
      "29. Model - fovea_align_r101_fpn_gn-head_mstrain_640-800_4x4\n",
      "30. Model - free_anchor_retinanet_r50_fpn\n",
      "31. Model - free_anchor_retinanet_r101_fpn\n",
      "32. Model - free_anchor_retinanet_x101_32x4d_fpn\n",
      "33. Model - atss_r50_fpn\n",
      "34. Model - pafpn_faster_rcnn_r50\n",
      "35. Model - faster_rcnn_r50_fpn_mdpool\n",
      "36. Model - faster_rcnn_r50_fpn_dpool\n"
     ]
    }
   ],
   "source": [
    "gtf.List_Models();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model_Params(model_name=\"free_anchor_retinanet_r101_fpn\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Hyper_Params(lr=0.02, momentum=0.9, weight_decay=0.0001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Training_Params(num_epochs=100, val_interval=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/16_mmdet/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_engine import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model_Params(\"work_dirs/config_updated/config_updated.py\", \n",
    "                 \"work_dirs/config_updated/latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_list = os.listdir(\"habcamseq0/images\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gtf.Predict(img_path=\"habcamseq0/images/\" + img_list[0],\n",
    "           out_img_path=\"result.jpg\",\n",
    "           thresh=0.8);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='result.jpg', width=490, height=640) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
